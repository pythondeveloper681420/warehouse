import streamlit as st
import requests
from bs4 import BeautifulSoup
import urllib.parse
import re  # Added re import

class SearchEngine:
    @staticmethod
    def _make_request(url, headers=None):
        """
        M√©todo utilit√°rio para fazer requisi√ß√µes HTTP
        """
        if headers is None:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept-Language': 'pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7'
            }
        try:
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            return response
        except Exception as e:
            st.error(f"Erro na requisi√ß√£o: {e}")
            return None

    @staticmethod
    def buscar_imagem_google_gratis(query):
        """
        Busca e retorna URLs de imagens do Google
        
        Args:
            query (str): Descri√ß√£o ou termo para buscar imagem
        
        Returns:
            list: Lista de URLs de imagens encontradas
        """
        try:
            # Codificar a query para URL
            query_encoded = urllib.parse.quote(query)
            
            # URL de busca de imagens do Google com par√¢metros adicionais
            url = f"https://www.google.com/search?tbm=isch&q={query_encoded}&tbs=isz:m"
            
            # Cabe√ßalhos para simular navegador
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
            
            # Fazer requisi√ß√£o
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            # Encontrar todas as ocorr√™ncias de URLs de imagens
            urls = re.findall(r'\["(https?://[^"]+)"', response.text)
            
            # Retornar lista de URLs √∫nicas, limitando a 10 resultados
            return list(set(urls))[:10]
        
        except Exception as e:
            st.error(f"Erro na busca de imagem do Google: {e}")
            return []

    @staticmethod
    def google_search(query, max_results=10, search_type='web'):
        """
        Realiza busca no Google
        """
        try:
            encoded_query = urllib.parse.quote(query)
            
            # URLs de busca espec√≠ficas por tipo
            search_urls = {
                'web': f"https://www.google.com/search?q={encoded_query}&lr=lang_pt",
                'images': f"https://www.google.com/search?q={encoded_query}&tbm=isch&lr=lang_pt",
                'shopping': f"https://www.google.com/search?q={encoded_query}&tbm=shop&lr=lang_pt",
                'local': f"https://www.google.com/search?q={encoded_query}+near+me&lr=lang_pt"    
            }
            
            url = search_urls.get(search_type, search_urls['web'])
            
            response = SearchEngine._make_request(url)
            if not response:
                return []
            
            results = []
            
            if search_type == 'images':
                # Use the new buscar_imagem_google_gratis method
                image_urls = SearchEngine.buscar_imagem_google_gratis(query)
                results = [
                    {
                        'image': url, 
                        'title': f"{query} - Imagem {i+1}"
                    } 
                    for i, url in enumerate(image_urls)
                ]
            
            # Mant√©m o c√≥digo original para outros tipos de busca
            elif search_type == 'web':
                soup = BeautifulSoup(response.text, 'html.parser')
                for result in soup.select('.g')[:max_results]:
                    title = result.select_one('h3')
                    link = result.select_one('a')
                    snippet = result.select_one('.VwiC3b')
                    
                    if title and link and snippet:
                        results.append({
                            'title': title.get_text(),
                            'href': link['href'],
                            'body': snippet.get_text()
                        })
  
            elif search_type == 'shopping':
                soup = BeautifulSoup(response.text, 'html.parser')
                
                for result in soup.select('.sh-dgr__grid-result')[:max_results]:
                    # Title extraction
                    title = result.select_one('.tAxDx')
                    
                    # Price extraction with multiple fallback methods
                    price_selectors = [
                        '.a8Pemb.OFFNJ',  # Primary price selector
                        '.kHxwFf .a8Pemb',
                        '.a__b',
                        '[data-price]'
                    ]
                    
                    price = None
                    for selector in price_selectors:
                        price_elem = result.select_one(selector)
                        if price_elem:
                            price = price_elem.get_text().strip()
                            break
                    
                    # Improved link extraction
                    # Improved link extraction
                    link_elem = result.select_one('a[href*="/shopping/product/"]')
                    if link_elem:
                        full_link = link_elem['href']
                        
                        # Check if the link is a relative URL
                        if full_link.startswith('/shopping/'):
                            full_link = f"https://www.google.com{full_link}"
                    else:
                        full_link = 'Link n√£o dispon√≠vel'
                    
                    if title and (price or link_elem):
                        results.append({
                            'title': title.get_text().strip(),
                            'href': full_link,
                            'price': price if price else 'Pre√ßo n√£o dispon√≠vel'
                        })
                
                return results
            
            elif search_type == 'local':
                soup = BeautifulSoup(response.text, 'html.parser')
                for result in soup.select('.g')[:max_results]:
                    title = result.select_one('h3')
                    link = result.select_one('a')
                    address = result.select_one('.rx78Hd')
                    
                    
                    if title and link:
                        # Fun√ß√£o para limpar o t√≠tulo
                        def limpar_string(texto):
                            return re.sub(r'[^a-zA-Z\s]', '', texto)
                        address_text = address.get_text() if address else f"https://www.google.com/maps/search/{limpar_string(title.decode_contents()).replace(' ', '+').lower()}",
                        results.append({
                            
                            'title': title.get_text(),
                            'href': link['href'],
                            'address': f"https://www.google.com/maps/search/{limpar_string(title.decode_contents()).replace(' ', '+').lower()}"
                        })
            
            return results
        
        except Exception as e:
            st.error(f"Erro na busca do Google: {e}")
            return []


    @staticmethod
    def bing_search(query, max_results=10, search_type='web'):
        """
        Realiza busca no Bing
        """
        try:
            encoded_query = urllib.parse.quote(query)
            
            # URLs de busca espec√≠ficas por tipo
            search_urls = {
                'web': f"https://www.bing.com/search?q={encoded_query}&setlang=pt",
                'news': f"https://www.bing.com/news/search?q={encoded_query}&setlang=pt",
                'images': f"https://www.bing.com/images/search?q={encoded_query}",
            }
            
            url = search_urls.get(search_type, search_urls['web'])
            
            response = SearchEngine._make_request(url)
            if not response:
                return []
            
            soup = BeautifulSoup(response.text, 'html.parser')
            results = []
            
            if search_type == 'web':
                for result in soup.select('.b_algo')[:max_results]:
                    title = result.select_one('h2')
                    link = result.select_one('a')
                    snippet = result.select_one('.b_caption p')
                    
                    if title and link and snippet:
                        results.append({
                            'title': title.get_text(),
                            'href': link['href'],
                            'body': snippet.get_text()
                        })
            
            elif search_type == 'images':
                for img in soup.select('.img_cont img')[:max_results]:
                    src = img.get('src', '')
                    alt = img.get('alt', 'Imagem sem t√≠tulo')
                    
                    if src and src.startswith(('http', 'data:')):
                        results.append({
                            'image': src,
                            'title': alt
                        })
            
            elif search_type == 'news':
                for result in soup.select('.news-card')[:max_results]:
                    title = result.select_one('.title')
                    link = result.select_one('a')
                    source = result.select_one('.source')
                    
                    if title and link:
                        results.append({
                            'title': title.get_text(),
                            'href': link['href'],
                            'source': source.get_text() if source else 'Fonte n√£o dispon√≠vel'
                        })
            
            return results
        
        except Exception as e:
            st.error(f"Erro na busca do Bing: {e}")
            return []


def main():
    st.set_page_config(page_title="Busca Avan√ßada", page_icon="üîç")
    st.title("üîç Busca Avan√ßada")
    
    # Barra lateral para configura√ß√µes
    st.sidebar.header("Configura√ß√µes de Busca")
    max_results = st.sidebar.slider("N√∫mero m√°ximo de resultados", 1, 30, 10)
    search_engine = st.sidebar.selectbox(
        "Selecione o Motor de Busca",
        ["Google", "Bing"]
    )
    
    if search_engine=='Google':
    # Sele√ß√£o do tipo de busca
        search_type = st.sidebar.selectbox(
            "Tipo de Busca",
            ["Web","Imagens", "Shopping", "Local"]
        )

    else: 
        # Sele√ß√£o do tipo de busca
        search_type = st.sidebar.selectbox(
            "Tipo de Busca",
            ["Web", "Not√≠cias", "Imagens"]
        )   
    
    # Campo de entrada para o termo de busca
    query = st.text_input("Digite seu termo de busca", placeholder="Ex: Python programming")
    
    # Bot√£o de busca
    if st.button("Buscar"):
        if query:
            # Exibir anima√ß√£o de carregamento
            with st.spinner("Buscando resultados..."):
                # Mapear tipos de busca para m√©todos
                search_type_map = {
                    "Web": "web",
                    "Not√≠cias": "news",
                    "Imagens": "images",
                    "Shopping": "shopping", 
                    "Local": "local"
                }
                
                # Realizar busca baseada no motor de busca e tipo selecionado
                if search_engine == "Google":
                    results = SearchEngine.google_search(query, max_results, search_type_map[search_type])
                else:
                    results = SearchEngine.bing_search(query, max_results, search_type_map[search_type])
            
            # Exibir resultados
            if results:
                if search_type == "Web":
                    st.subheader("üî§ Resultados de Texto")
                    for result in results:
                        with st.container():
                            st.markdown(f"### {result.get('title', 'Sem t√≠tulo')}")
                            st.write(result.get('body', 'Sem descri√ß√£o'))
                            st.markdown(f"üîó [Link]({result.get('href', '#')})")
                            st.divider()
                
                elif search_type == "Not√≠cias":
                    st.subheader("üì∞ Resultados de Not√≠cias")
                    for result in results:
                        with st.container():
                            st.markdown(f"### {result.get('title', 'Sem t√≠tulo')}")
                            st.write(f"Fonte: {result.get('source', 'Fonte n√£o dispon√≠vel')}")
                            st.markdown(f"üîó [Link]({result.get('href', '#')})")
                            st.divider()
                
                elif search_type == "Imagens":
                    st.subheader("üñºÔ∏è Resultados de Imagens")
                    cols = st.columns(3)
                    for i, img in enumerate(results):
                        col = cols[i % 3]
                        with col:
                            st.image(img.get('image'), caption=img.get('title', 'Imagem'))
                
                elif search_type == "Shopping":
                    st.subheader("üõçÔ∏è Resultados de Shopping")
                    for result in results:
                        with st.container():
                            st.markdown(f"### {result.get('title', 'Sem t√≠tulo')}")
                            st.write(f"Pre√ßo: {result.get('price', 'Pre√ßo n√£o dispon√≠vel')}")
                            st.markdown(f"üîó [Link]({result.get('href', '#')})")
                            st.divider()
                
                elif search_type == "Local":
                    st.subheader("üìç Resultados Locais")
                    for result in results:
                        with st.container():
                            st.markdown(f"### {result.get('title', 'Sem t√≠tulo')}")
                            st.write(f"Endere√ßo: {result.get('address', 'Endere√ßo n√£o dispon√≠vel')}")
                            st.markdown(f"üîó [Link]({result.get('href', '#')})")
                            st.divider()
            else:
                st.warning(f"Nenhum resultado encontrado para {search_type}.")
        else:
            st.warning("Por favor, insira um termo de busca.")

if __name__ == "__main__":
    main()